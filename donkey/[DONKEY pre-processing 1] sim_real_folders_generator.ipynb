{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "637ee4c2",
   "metadata": {},
   "source": [
    "# Folders generation for processing DONKEY\n",
    "This notebook uses the simulated and real data to produce the folders for training and evaluation\n",
    "\n",
    "## Usage:\n",
    "Run all cells\n",
    "\n",
    "## Requirements:\n",
    "./content/datasets/data_in/objects/ must contain folders /sim/ & /real/ each with the sim and real images and driving logs.\n",
    "\n",
    "## Outputs:\n",
    "./content/datasets/processed_data/real \\\n",
    "./content/datasets/processed_data/sim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65585df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import PIL.Image as Image\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import h5py\n",
    "import numpy as np\n",
    "import PIL.Image as Image\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "import json\n",
    "\n",
    "img = np.array(Image.open(\"./content/datasets/data_in/objects/real/26_cam-image_array_.jpg\"))\n",
    "obj_ids = np.unique(img)\n",
    "print(obj_ids)\n",
    "\n",
    "def natural_sort_key(s):\n",
    "    return [int(text) if text.isdigit() else text.lower() for text in re.split(r'(\\d+)', s)]\n",
    "\n",
    "def load_data(images_folder):\n",
    "  raw_image=[]\n",
    "  image_files = sorted(os.listdir(images_folder),key=natural_sort_key)\n",
    "  for image_file in image_files:\n",
    "      image = cv2.imread(images_folder+image_file)\n",
    "      raw_image.append(image)\n",
    "  return raw_image\n",
    "\n",
    "\n",
    "raw_image_sim = []\n",
    "raw_image_real = []\n",
    "\n",
    "\n",
    "print(\"-STARTING real- \")\n",
    "images_folder = f\"./content/datasets/data_in/objects/real/\"\n",
    "raw_image_real=load_data(images_folder)\n",
    "\n",
    "print(\"-STARTING sim- \")\n",
    "images_folder = f\"./content/datasets/data_in/objects/sim/\"\n",
    "raw_image_sim=load_data(images_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54edbd5d-9513-4f1b-a6dd-d9e2513574f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 100,1):\n",
    "      print(i)\n",
    "      # Create a 2x2 grid of subplots\n",
    "      fig, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
    "      plt.subplots_adjust(wspace=0.2, hspace=0.4)\n",
    "\n",
    "      # Plot the real and fake images side by side in the first row\n",
    "      axs[0].imshow(cv2.cvtColor(raw_image_real[i], cv2.COLOR_BGR2RGB))\n",
    "      axs[0].set_title('Real Image')\n",
    "      axs[1].imshow(cv2.cvtColor(raw_image_sim[i], cv2.COLOR_BGR2RGB))\n",
    "      axs[1].set_title('Sim Image')\n",
    "      for ax in axs.flat:\n",
    "          ax.set_xticks([])\n",
    "          ax.set_yticks([])\n",
    "\n",
    "      # Show the plot for the current iteration\n",
    "      plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df362159-82df-4f49-989e-e1e132737127",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_index=\"image\"\n",
    "def find_lowest_dimensions(images_list1, images_list2):\n",
    "    # Find the lowest height and width across both lists\n",
    "    lowest_height = min(images_list1[0].shape[0], images_list2[0].shape[0])\n",
    "    lowest_width = min(images_list1[0].shape[1], images_list2[0].shape[1])\n",
    "    return lowest_height, lowest_width\n",
    "\n",
    "def crop_images_to_lowest_dimensions(images_list, lowest_height, lowest_width):\n",
    "    cropped_images = [image[:lowest_height, :lowest_width,:] for image in images_list]\n",
    "    return cropped_images\n",
    "\n",
    "def crop_1d_to_lowest_dimensions(images_list, lowest_height, lowest_width):\n",
    "    cropped_images = [image[:lowest_height, :lowest_width] for image in images_list]\n",
    "    return cropped_images\n",
    "\n",
    "lowest_height=10000\n",
    "lowest_width=10000\n",
    "height, width = find_lowest_dimensions(raw_image_real, raw_image_sim)\n",
    "lowest_height=min(height,lowest_height)\n",
    "lowest_width=min(width,lowest_width)\n",
    "print(lowest_height,lowest_width)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5998f77b-9ff0-4a22-88e2-3e426a3c291a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loaded_dictionary_images_real={}\n",
    "loaded_dictionary_images_sim={}\n",
    "\n",
    "loaded_dictionary_images_real[dataset_index] = crop_images_to_lowest_dimensions(raw_image_real, lowest_height, lowest_width)\n",
    "loaded_dictionary_images_sim[dataset_index] = crop_images_to_lowest_dimensions(raw_image_sim, lowest_height, lowest_width)\n",
    "\n",
    "train_indexes_gan = {}\n",
    "test_indexes_gan = {}\n",
    "\n",
    "\n",
    "# pattern = 'ttvttvttvt'\n",
    "pattern = 'tttttttttt'\n",
    "pattern_pointer = 0\n",
    "train_dataset_indices_inner = []\n",
    "test_dataset_indices_inner = []\n",
    "\n",
    "for index in range(0, min(len(loaded_dictionary_images_real[dataset_index]),len(loaded_dictionary_images_sim[dataset_index]))):\n",
    "    pattern_char = pattern[pattern_pointer]\n",
    "    if pattern_char == 't':\n",
    "        train_dataset_indices_inner.append(index)\n",
    "    else:\n",
    "        test_dataset_indices_inner.append(index)\n",
    "    pattern_pointer = (pattern_pointer + 1) % len(pattern)\n",
    "train_indexes_gan[dataset_index]=train_dataset_indices_inner\n",
    "test_indexes_gan[dataset_index]=test_dataset_indices_inner\n",
    "\n",
    "print(\"GAN train and test\")\n",
    "print(\"Dataset\", dataset_index)\n",
    "print(\"Train: \",len(train_indexes_gan[dataset_index]))\n",
    "print(\"Test: \",len(test_indexes_gan[dataset_index]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad2ac77-1937-4155-af0f-277edafba429",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset_index)\n",
    "for i in range(0, 100):\n",
    "  # Create a 2x2 grid of subplots\n",
    "  fig, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
    "  plt.subplots_adjust(wspace=0.2, hspace=0.4)\n",
    "\n",
    "  # Plot the real and fake images side by side in the first row\n",
    "  axs[0].imshow(cv2.cvtColor(loaded_dictionary_images_real[dataset_index][i], cv2.COLOR_BGR2RGB))\n",
    "  axs[0].set_title('Real Image')\n",
    "  axs[1].imshow(cv2.cvtColor(loaded_dictionary_images_sim[dataset_index][i], cv2.COLOR_BGR2RGB))\n",
    "  axs[1].set_title('Sim Image')\n",
    "\n",
    "  for ax in axs.flat:\n",
    "      ax.set_xticks([])\n",
    "      ax.set_yticks([])\n",
    "\n",
    "  # Show the plot for the current iteration\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ffe4bc6-f4cc-4f03-afad-b8fe36223c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_sim_real_outputs(real_path,sim_path):\n",
    "          dataset_index=\"image\"\n",
    "          print(dataset_index)\n",
    "          counter=0\n",
    "          for i in train_indexes_gan[dataset_index]:\n",
    "                counter+=1\n",
    "                input_image_real = np.array(loaded_dictionary_images_real[dataset_index][i])\n",
    "                input_image_real = tf.convert_to_tensor(input_image_real.astype(np.uint8), np.uint8)\n",
    "                input_image_real = tf.reverse(input_image_real, axis=[-1])\n",
    "                \n",
    "                png_image = tf.image.encode_png(input_image_real)\n",
    "                os.makedirs('./content/datasets/processed_data/'+real_path+'/', exist_ok=True)\n",
    "                with open('./content/datasets/processed_data/'+real_path+'/'+str(dataset_index)+'_'+str(i)+'.png', 'wb') as f:\n",
    "                  f.write(png_image.numpy())\n",
    "                \n",
    "        \n",
    "                input_image_sim = np.array(loaded_dictionary_images_sim[dataset_index][i])\n",
    "                input_image_sim = tf.convert_to_tensor(input_image_sim.astype(np.uint8), np.uint8)\n",
    "                input_image_sim = tf.reverse(input_image_sim, axis=[-1])\n",
    "                png_image = tf.image.encode_png(input_image_sim)\n",
    "                os.makedirs('./content/datasets/processed_data/'+sim_path+'/', exist_ok=True)\n",
    "                with open('./content/datasets/processed_data/'+sim_path+'/'+str(dataset_index)+'_'+str(i)+'.png', 'wb') as f:\n",
    "                  f.write(png_image.numpy())\n",
    "                \n",
    "\n",
    "                # error_lane=0\n",
    "                  \n",
    "\n",
    "                # error_data_sim = {\n",
    "                #     \"sim_real\": error_lane,\n",
    "                # }\n",
    "\n",
    "                # output_folder = \"./content/output_plots/\"+sim_path+\"_lane_error/\"\n",
    "                # os.makedirs(output_folder, exist_ok=True)\n",
    "                # output_path = output_folder + str(dataset_index) + \"_\" + str(i) +\".json\"\n",
    "                # with open(output_path, \"w\") as json_file:\n",
    "                #     json.dump(error_data_sim, json_file, indent=4)\n",
    "\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b686163-f7f4-4c83-8786-4b710482874b",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_sim_real_outputs(\"real\",\"sim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207bb5a3-b581-43d0-af3b-0ea0bedee594",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a1e22f-641b-4848-ac75-b0fd91c13aec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e36f46-1523-420f-84b2-b399c2e630bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff41fe9-39ed-4c9e-942d-5589a0d00801",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670f64a2-8080-4fd0-b1b4-f9e5e6a5b726",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a8cdbb-dbef-48e2-8ad2-da9615de1113",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5cf4d7-9aec-4584-8dc0-ddb7e3c29da5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c44d89-92fb-4ab9-bba4-8c4038f585cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3536d4-3bff-4704-a9ae-8e2055a4b813",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce319727-486a-492c-a27b-57849bb0833c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f78ca43-8cd1-4434-8195-8cb4825d44a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917da750-7d3a-487b-b8a0-49b7df2df021",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7256cf56-ace9-46fa-83b6-4a5df54f292e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f522f1-987f-45a3-a27c-a3f476a6a9b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4b2276-87be-4260-973f-1b155ea314df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b904ab8-35fa-4f39-8ab5-3155859da904",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc629af-6d6f-4156-b523-62add660e6f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9790c9a4-88e7-4408-9009-999e0d4f992b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfEnv4",
   "language": "python",
   "name": "tfenv4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
