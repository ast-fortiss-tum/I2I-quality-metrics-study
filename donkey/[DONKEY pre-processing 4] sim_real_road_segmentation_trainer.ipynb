{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bcabe20",
   "metadata": {},
   "source": [
    "# Train segmentation model for DONKEY\n",
    "This notebook trains the segmentation model\n",
    "\n",
    "## Usage:\n",
    "Run all cells\n",
    "\n",
    "## Requirements:\n",
    "./content/datasets/processed_data/sim_rectified \\\n",
    "./content/datasets/processed_data/sim_rectified_mask_retouched \\\n",
    "./content/datasets/processed_data/real_rectified \\\n",
    "./content/datasets/processed_data/real_rectified_mask_retouched\n",
    "\n",
    "## Outputs:\n",
    "./content/segmentation_checkpoints/Model_weights.hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52b8eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import PIL.Image as Image\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import h5py\n",
    "import numpy as np\n",
    "import PIL.Image as Image\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "\n",
    "img = np.array(Image.open(\"./content/datasets/data_in/objects/real/26_cam-image_array_.jpg\"))\n",
    "obj_ids = np.unique(img)\n",
    "print(obj_ids)\n",
    "\n",
    "def natural_sort_key(s):\n",
    "    return [int(text) if text.isdigit() else text.lower() for text in re.split(r'(\\d+)', s)]\n",
    "\n",
    "def load_data(images_folder):\n",
    "  raw_image=[]\n",
    "  image_files = sorted(os.listdir(images_folder),key=natural_sort_key) \n",
    "  for image_file in image_files:\n",
    "      if image_file[0]!=\".\":\n",
    "          image = mpimg.imread(images_folder+image_file)\n",
    "          if (image_file.split(\".\")[-1]==\"png\"):\n",
    "              image=image[:,:,:3]\n",
    "              image = (image * 255).astype(np.uint8)\n",
    "          raw_image.append(image)\n",
    "  return raw_image\n",
    "\n",
    "\n",
    "def load_data_mask(images_folder):\n",
    "  raw_image=[]\n",
    "  image_files = sorted(os.listdir(images_folder),key=natural_sort_key)\n",
    "  #print(image_files)    \n",
    "  for image_file in image_files:\n",
    "      if image_file[0]==\".\":\n",
    "          break\n",
    "      image = mpimg.imread(images_folder+image_file)\n",
    "      if (image_file.split(\".\")[-1]==\"png\"):\n",
    "          image = (image * 255).astype(np.uint8)\n",
    "      raw_image.append(image)\n",
    "  return raw_image\n",
    "\n",
    "\n",
    "raw_image_sim = []\n",
    "raw_image_real = []\n",
    "\n",
    "print(\"-STARTING sim- \")\n",
    "images_folder = f\"./content/datasets/processed_data/sim_rectified/\"\n",
    "raw_image_sim=load_data(images_folder)\n",
    "images_folder = f\"./content/datasets/processed_data/sim_rectified_mask_retouched/\"\n",
    "raw_mask_sim=load_data_mask(images_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "896006b0-257c-4511-9d2d-56c7c72a154d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-STARTING real- \n"
     ]
    }
   ],
   "source": [
    "print(\"-STARTING real- \")\n",
    "images_folder = f\"./content/datasets/processed_data/real/\"\n",
    "raw_image_real=load_data(images_folder)\n",
    "images_folder = f\"./content/datasets/processed_data/real_mask_retouched/\"\n",
    "raw_mask_real=load_data_mask(images_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ac9bbc-c0e3-4d06-8411-cc51bd49c226",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(raw_image_sim))\n",
    "print(len(raw_mask_sim))\n",
    "for i in range(0, 100,1):\n",
    "      print(i)\n",
    "      # Create a 2x2 grid of subplots\n",
    "      fig, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
    "      plt.subplots_adjust(wspace=0.2, hspace=0.4)\n",
    "\n",
    "      # Plot the real and fake images side by side in the first row\n",
    "      axs[0].imshow(raw_image_sim[i])\n",
    "      axs[0].set_title('Sim Image')\n",
    "      axs[1].imshow(raw_mask_sim[i])\n",
    "      axs[1].set_title('Mask Image')\n",
    "      for ax in axs.flat:\n",
    "          ax.set_xticks([])\n",
    "          ax.set_yticks([])\n",
    "\n",
    "      # Show the plot for the current iteration\n",
    "      plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3a1cb1-9aef-4ddc-bcc7-4cb0ae687c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(raw_image_real))\n",
    "print(len(raw_mask_real))\n",
    "for i in range(0, 100,1):\n",
    "      print(i)\n",
    "      # Create a 2x2 grid of subplots\n",
    "      fig, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
    "      plt.subplots_adjust(wspace=0.2, hspace=0.4)\n",
    "\n",
    "      # Plot the real and fake images side by side in the first row\n",
    "      axs[0].imshow(raw_image_real[i])\n",
    "      axs[0].set_title('Sim Image')\n",
    "      axs[1].imshow(raw_mask_real[i])\n",
    "      axs[1].set_title('Mask Image')\n",
    "      for ax in axs.flat:\n",
    "          ax.set_xticks([])\n",
    "          ax.set_yticks([])\n",
    "\n",
    "      # Show the plot for the current iteration\n",
    "      plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b28996ff-c274-46ef-9457-e7f756d928e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def map_to_desired_structure(input_image, output_image):\n",
    "    return {'pixel_values': tf.cast(input_image, tf.float32), 'labels': tf.cast(output_image, tf.float32)}\n",
    "\n",
    "def map_values(value):\n",
    "    if value in [128]:\n",
    "        return 1\n",
    "    elif value in [255]:\n",
    "        return 2\n",
    "    else:\n",
    "        return 0\n",
    "    return value\n",
    "def create_tf_dataset(input_dict, output_dict, input_indices):\n",
    "    # Make sure input_indices and output_indices have the same length\n",
    "\n",
    "    # Create lists to store input and output images\n",
    "    input_images = []\n",
    "    output_images = []\n",
    "\n",
    "    # Iterate over the indices and extract the corresponding images\n",
    "\n",
    "    print(\"Elements number: \",len(input_indices))\n",
    "    for index in input_indices:\n",
    "        if index < len(input_dict):\n",
    "            input_images.append(input_dict[index])\n",
    "\n",
    "\n",
    "    vectorized_map = np.vectorize(map_values)\n",
    "    for index in input_indices:\n",
    "        if index < len(output_dict):\n",
    "            label_value = output_dict[index]\n",
    "            output_images.append(vectorized_map(label_value))\n",
    "    print(\"Processing\")\n",
    "    # Convert lists to numpy arrays\n",
    "    input_images = np.array(input_images)\n",
    "    # input_images = tf.reverse(input_images, axis=[-1])\n",
    "    input_images = tf.transpose(input_images, (0,3, 1, 2))\n",
    "    output_images = np.array(output_images)\n",
    "\n",
    "    # Create TensorFlow dataset from numpy arrays\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((input_images, output_images))\n",
    "    print(\"Mapping\")\n",
    "\n",
    "    dataset = dataset.map(map_to_desired_structure)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1078e9-f1d1-4aa3-a5ab-4b5d763c7266",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indexes_gan = {}\n",
    "test_indexes_gan = {}\n",
    "\n",
    "\n",
    "pattern = 'ttvttvttvt'\n",
    "pattern_pointer = 0\n",
    "train_dataset_indices_inner = []\n",
    "test_dataset_indices_inner = []\n",
    "\n",
    "for index in range(0, min(len(raw_image_sim),len(raw_mask_sim))):\n",
    "    pattern_char = pattern[pattern_pointer]\n",
    "    if pattern_char == 't':\n",
    "        train_dataset_indices_inner.append(index)\n",
    "    else:\n",
    "        test_dataset_indices_inner.append(index)\n",
    "    pattern_pointer = (pattern_pointer + 1) % len(pattern)\n",
    "train_indexes=train_dataset_indices_inner\n",
    "test_indexes=test_dataset_indices_inner\n",
    "\n",
    "print(\"GAN train and test\")\n",
    "print(\"Train: \",len(train_indexes))\n",
    "print(\"Test: \",len(test_indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4a95fc-46a6-4315-bfc8-d1b30430642e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_dataset_train_sim = create_tf_dataset(raw_image_sim, raw_mask_sim, train_indexes)\n",
    "tf_dataset_test_sim = create_tf_dataset(raw_image_sim, raw_mask_sim, test_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b3ebc0-1844-443c-8812-4bf44e7c0d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_dataset_train_real = create_tf_dataset(raw_image_real, raw_mask_real, train_indexes)\n",
    "tf_dataset_test_real = create_tf_dataset(raw_image_real, raw_mask_real, test_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c514ca49-e39f-4c58-acc4-17e1c9aa2f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1303f219-7c21-4c02-b816-d49863e92334",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend\n",
    "\n",
    "image_size = 512\n",
    "mean = tf.constant([0.485, 0.456, 0.406])\n",
    "std = tf.constant([0.229, 0.224, 0.225])\n",
    "\n",
    "\n",
    "def normalize(input_image, input_mask):\n",
    "    input_image = tf.image.convert_image_dtype(input_image, tf.float32)\n",
    "    input_image = (input_image - mean) / tf.maximum(std, backend.epsilon())\n",
    "    input_mask -= 1\n",
    "    return input_image, input_mask\n",
    "\n",
    "\n",
    "def load_image(datapoint):\n",
    "    input_image = tf.image.resize(datapoint[\"image\"], (image_size, image_size))\n",
    "    input_mask = tf.image.resize(\n",
    "        datapoint[\"segmentation_mask\"],\n",
    "        (image_size, image_size),\n",
    "        method=\"bilinear\",\n",
    "    )\n",
    "\n",
    "    input_image, input_mask = normalize(input_image, input_mask)\n",
    "    input_image = tf.transpose(input_image, (2, 0, 1))\n",
    "    return {\"pixel_values\": input_image, \"labels\": tf.squeeze(input_mask)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e361f3e-ac5c-4492-b3c6-0d275dc54f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds =tf_dataset_train_sim\n",
    "test_ds =tf_dataset_test_sim\n",
    "train_ds2 =tf_dataset_train_real\n",
    "test_ds2 =tf_dataset_test_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9cb88df-4c80-42a0-8ccd-7b3ee5e6e8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto = tf.data.AUTOTUNE\n",
    "batch_size = 4\n",
    "\n",
    "train_ds = (\n",
    "    train_ds\n",
    "    .shuffle(batch_size * 10)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(auto)\n",
    "    .cache()\n",
    ")\n",
    "\n",
    "test_ds = (\n",
    "    test_ds\n",
    "    .shuffle(batch_size * 10)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(auto)\n",
    "    .cache()\n",
    ")\n",
    "\n",
    "train_ds2 = (\n",
    "    train_ds2\n",
    "    .shuffle(batch_size * 10)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(auto)\n",
    "    .cache()\n",
    ")\n",
    "\n",
    "test_ds2 = (\n",
    "    test_ds2\n",
    "    .shuffle(batch_size * 10)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(auto)\n",
    "    .cache()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e7edaca-dd1f-400f-9bdf-d4cb898ba77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pixel_values': TensorSpec(shape=(None, 3, 140, 320), dtype=tf.float32, name=None), 'labels': TensorSpec(shape=(None, 140, 320), dtype=tf.float32, name=None)}\n",
      "{'pixel_values': TensorSpec(shape=(None, 3, 140, 320), dtype=tf.float32, name=None), 'labels': TensorSpec(shape=(None, 140, 320), dtype=tf.float32, name=None)}\n",
      "{'pixel_values': TensorSpec(shape=(None, 3, 140, 320), dtype=tf.float32, name=None), 'labels': TensorSpec(shape=(None, 140, 320), dtype=tf.float32, name=None)}\n"
     ]
    }
   ],
   "source": [
    "print(train_ds.element_spec)\n",
    "print(test_ds.element_spec)\n",
    "print(test_ds2.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8348d7fc-abe8-4a54-b513-95d1031bbd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(display_list):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "\n",
    "    title = [\"Input Image\", \"True Mask\", \"Predicted Mask\"]\n",
    "\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i + 1)\n",
    "        plt.title(title[i])\n",
    "        print(display_list[i].shape)\n",
    "        plt.imshow(tf.keras.utils.array_to_img(display_list[i]))\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "for samples in train_ds2.take(10):\n",
    "    sample_image, sample_mask = samples[\"pixel_values\"][0], samples[\"labels\"][0]\n",
    "    sample_image = tf.transpose(sample_image, (1, 2, 0))\n",
    "    sample_mask = tf.expand_dims(sample_mask, -1)\n",
    "    display([sample_image, sample_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da88464-9969-4e64-8dbf-14f636667079",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFSegformerForSemanticSegmentation\n",
    "\n",
    "model_checkpoint = \"nvidia/mit-b0\"\n",
    "id2label = {0: \"not_important\", 1: \"road\", 2: \"marking\"}\n",
    "label2id = {label: id for id, label in id2label.items()}\n",
    "num_labels = len(id2label)\n",
    "model = TFSegformerForSemanticSegmentation.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    num_labels=num_labels,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    ignore_mismatched_sizes=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa2abb29-8179-47ec-9f63-c7db6ac298f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.00006\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d04949e6-8996-467d-a93e-eee5202b185c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "def create_mask(pred_mask):\n",
    "    pred_mask = tf.math.argmax(pred_mask, axis=1)\n",
    "    pred_mask = tf.expand_dims(pred_mask, -1)\n",
    "    return pred_mask[0]\n",
    "\n",
    "\n",
    "def show_predictions(dataset=None, num=1):\n",
    "    if dataset:\n",
    "        for sample in dataset.take(num):\n",
    "            images, masks = sample[\"pixel_values\"], sample[\"labels\"]\n",
    "            masks = tf.expand_dims(masks, -1)\n",
    "            pred_masks = model.predict(images).logits\n",
    "            images = tf.transpose(images, (0, 2, 3, 1))\n",
    "            display([images[0], masks[0], create_mask(pred_masks)])\n",
    "    else:\n",
    "        display(\n",
    "            [\n",
    "                sample_image,\n",
    "                sample_mask,\n",
    "                create_mask(model.predict(tf.expand_dims(sample_image, 0))),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "\n",
    "class DisplayCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, dataset, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        #clear_output(wait=True)\n",
    "        show_predictions(self.dataset)\n",
    "        print(\"\\nSample Prediction after epoch {}\\n\".format(epoch + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99dd04a1-0ad2-4769-9cac-f2e979b7a61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_file_path2 = \"./content/segmentation_checkpoints/Model_weights.hdf5\"\n",
    "model.load_weights(checkpoint_file_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0f9b30-a5f1-4a15-bf55-b0bebf9d1cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "for i in range(0,3):\n",
    "    print(\"SIM\")\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=test_ds,\n",
    "        callbacks=[DisplayCallback(test_ds)],\n",
    "        epochs=epochs,\n",
    "    )\n",
    "    print(\"REAL\")\n",
    "    history = model.fit(\n",
    "        train_ds2,\n",
    "        validation_data=test_ds2,\n",
    "        callbacks=[DisplayCallback(test_ds2)],\n",
    "        epochs=epochs,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c9888b20-b8c4-42b4-8fa3-3e0cd46c38c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_file_path = \"./content/segmentation_checkpoints/Model_weights.hdf5\"\n",
    "model.save_weights(checkpoint_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41f3d18-b5f8-4b8a-8380-346cc77c2281",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_predictions(test_ds2, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea7409d-2ea2-43a1-8eef-2ee140a7ebbd",
   "metadata": {},
   "source": [
    "REWATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "31f53b15-c30e-4e6f-ad68-82716e7b959b",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_file_path2 = \"./content/segmentation_checkpoints/Model_weights.hdf5\"\n",
    "model.load_weights(checkpoint_file_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "29116743-1cee-411e-856c-b597360b6c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def savepred(display_list,id,domain):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "\n",
    "    title = [\"Input Image\", \"True Mask\", \"Predicted Mask\"]\n",
    "\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i + 1)\n",
    "        plt.title(title[i])\n",
    "        print(display_list[i].shape)\n",
    "        plt.imshow(tf.keras.utils.array_to_img(display_list[i]))\n",
    "        plt.axis(\"off\")\n",
    "    save_path=\"./content/output_plots/predicted_mask_\"+str(domain)+\"/img_\"+str(id)+\".png\"\n",
    "    plt.savefig(save_path)\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aebca219-89f9-460f-a23b-83abab9ba0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predictions(domain,dataset=None, num=1):\n",
    "    if dataset:\n",
    "        for i,sample in enumerate(dataset.take(num)):\n",
    "            images, masks = sample[\"pixel_values\"], sample[\"labels\"]\n",
    "            masks = tf.expand_dims(masks, -1)\n",
    "            pred_masks = model.predict(images).logits\n",
    "            images = tf.transpose(images, (0, 2, 3, 1))\n",
    "            savepred([images[0], masks[0], create_mask(pred_masks)],i,domain)\n",
    "    else:\n",
    "        savepred(\n",
    "            [\n",
    "                sample_image,\n",
    "                sample_mask,\n",
    "                create_mask(model.predict(tf.expand_dims(sample_image, 0))),\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec43fa0-08ad-40c0-8ba0-120167b2acbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_predictions(\"sim\",test_ds, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a1e952-513c-4312-a81e-729085105e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_predictions(\"real\",test_ds2, 1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfEnv4",
   "language": "python",
   "name": "tfenv4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
