{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51861830-ee19-45bc-bca0-a068da16677b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import PIL.Image as Image\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import h5py\n",
    "import numpy as np\n",
    "import PIL.Image as Image\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "import json\n",
    "\n",
    "img = np.array(Image.open(\"./content/datasets/data_in/objects_testing/real/tub320x240_test/445_cam-image_array_.jpg\"))\n",
    "obj_ids = np.unique(img)\n",
    "print(obj_ids)\n",
    "\n",
    "def natural_sort_key(s):\n",
    "    return [int(text) if text.isdigit() else text.lower() for text in re.split(r'(\\d+)', s)]\n",
    "\n",
    "def load_data(images_folder):\n",
    "  raw_image=[]\n",
    "  gt=[]\n",
    "  image_files = sorted(os.listdir(images_folder),key=natural_sort_key)\n",
    "  for image_file in image_files:\n",
    "      if image_file.split(\".\")[-1]==\"jpg\":\n",
    "          image = cv2.imread(images_folder+image_file)\n",
    "          raw_image.append(image)\n",
    "      if image_file.split(\".\")[-1]==\"json\" and image_file!='meta.json':\n",
    "          with open(images_folder+image_file, 'r') as json_file:\n",
    "            data = json.load(json_file)\n",
    "            user_angle = float(data.get('user/angle', None))\n",
    "            gt.append(user_angle)\n",
    "  return raw_image,gt\n",
    "\n",
    "\n",
    "raw_image_sim = []\n",
    "raw_image_real = []\n",
    "\n",
    "\n",
    "print(\"-STARTING real- \")\n",
    "images_folder = f\"./content/datasets/data_in/objects_testing/real/tub320x240_test/\"\n",
    "raw_image_real,gt_real=load_data(images_folder)\n",
    "\n",
    "print(\"-STARTING sim- \")\n",
    "images_folder = f\"./content/datasets/data_in/objects_testing/sim/tub320x240_test/\"\n",
    "raw_image_sim,gt_sim=load_data(images_folder)\n",
    "\n",
    "\n",
    "print(\"-STARTING real- \")\n",
    "images_folder = f\"./content/datasets/data_in/objects_testing/real/tub320x240_train/\"\n",
    "raw_image_real_train,gt_real_train=load_data(images_folder)\n",
    "\n",
    "print(\"-STARTING sim- \")\n",
    "images_folder = f\"./content/datasets/data_in/objects_testing/sim/tub320x240_train/\"\n",
    "raw_image_sim_train,gt_sim_train=load_data(images_folder)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54edbd5d-9513-4f1b-a6dd-d9e2513574f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 100,10):\n",
    "      print(i)\n",
    "      # Create a 2x2 grid of subplots\n",
    "      fig, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
    "      plt.subplots_adjust(wspace=0.2, hspace=0.4)\n",
    "\n",
    "      # Plot the real and fake images side by side in the first row\n",
    "      axs[0].imshow(cv2.cvtColor(raw_image_real[i], cv2.COLOR_BGR2RGB))\n",
    "      axs[0].set_title(str(gt_real[i]))\n",
    "      axs[1].imshow(cv2.cvtColor(raw_image_sim[i], cv2.COLOR_BGR2RGB))\n",
    "      axs[1].set_title(str(gt_sim[i]))\n",
    "      for ax in axs.flat:\n",
    "          ax.set_xticks([])\n",
    "          ax.set_yticks([])\n",
    "\n",
    "      # Show the plot for the current iteration\n",
    "      plt.show()\n",
    "\n",
    "for i in range(0, 100,1):\n",
    "      print(i)\n",
    "      # Create a 2x2 grid of subplots\n",
    "      fig, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
    "      plt.subplots_adjust(wspace=0.2, hspace=0.4)\n",
    "\n",
    "      # Plot the real and fake images side by side in the first row\n",
    "      axs[0].imshow(cv2.cvtColor(raw_image_real_train[i], cv2.COLOR_BGR2RGB))\n",
    "      axs[0].set_title(str(gt_real_train[i]))\n",
    "      axs[1].imshow(cv2.cvtColor(raw_image_sim_train[i], cv2.COLOR_BGR2RGB))\n",
    "      axs[1].set_title(str(gt_sim_train[i]))\n",
    "      for ax in axs.flat:\n",
    "          ax.set_xticks([])\n",
    "          ax.set_yticks([])\n",
    "\n",
    "      # Show the plot for the current iteration\n",
    "      plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df362159-82df-4f49-989e-e1e132737127",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_index=\"0001\"\n",
    "def find_lowest_dimensions(images_list1, images_list2):\n",
    "    # Find the lowest height and width across both lists\n",
    "    lowest_height = min(images_list1[0].shape[0], images_list2[0].shape[0])\n",
    "    lowest_width = min(images_list1[0].shape[1], images_list2[0].shape[1])\n",
    "    return lowest_height, lowest_width\n",
    "\n",
    "def crop_images_to_lowest_dimensions(images_list, lowest_height, lowest_width):\n",
    "    cropped_images = [image[100:, :lowest_width,:] for image in images_list]\n",
    "    return cropped_images\n",
    "\n",
    "lowest_height=140\n",
    "lowest_width=10000\n",
    "height, width = find_lowest_dimensions(raw_image_real, raw_image_sim)\n",
    "lowest_height=min(height,lowest_height)\n",
    "lowest_width=min(width,lowest_width)\n",
    "print(lowest_height,lowest_width)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5998f77b-9ff0-4a22-88e2-3e426a3c291a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN train and test\n",
      "Dataset 0001\n",
      "Train:  3657\n",
      "Test:  262\n"
     ]
    }
   ],
   "source": [
    "\n",
    "loaded_dictionary_images_real={}\n",
    "loaded_dictionary_images_sim={}\n",
    "\n",
    "loaded_dictionary_gt_real={}\n",
    "loaded_dictionary_gt_sim={}\n",
    "\n",
    "loaded_dictionary_images_real[dataset_index] = crop_images_to_lowest_dimensions(raw_image_real, lowest_height, lowest_width)\n",
    "loaded_dictionary_images_sim[dataset_index] = crop_images_to_lowest_dimensions(raw_image_sim, lowest_height, lowest_width)\n",
    "loaded_dictionary_gt_real[dataset_index] = gt_real\n",
    "loaded_dictionary_gt_sim[dataset_index] = gt_sim\n",
    "\n",
    "loaded_dictionary_images_real_train={}\n",
    "loaded_dictionary_images_sim_train={}\n",
    "\n",
    "loaded_dictionary_gt_real_train={}\n",
    "loaded_dictionary_gt_sim_train={}\n",
    "\n",
    "loaded_dictionary_images_real_train[dataset_index] = crop_images_to_lowest_dimensions(raw_image_real_train, lowest_height, lowest_width)\n",
    "loaded_dictionary_images_sim_train[dataset_index] = crop_images_to_lowest_dimensions(raw_image_sim_train, lowest_height, lowest_width)\n",
    "loaded_dictionary_gt_real_train[dataset_index] = gt_real_train\n",
    "loaded_dictionary_gt_sim_train[dataset_index] = gt_sim_train\n",
    "\n",
    "\n",
    "train_indexes_gan = {}\n",
    "test_indexes_gan = {}\n",
    "\n",
    "\n",
    "pattern = 'vvvvvvvvvv'\n",
    "pattern_pointer = 0\n",
    "train_dataset_indices_inner = []\n",
    "test_dataset_indices_inner = []\n",
    "\n",
    "for index in range(0, min(len(loaded_dictionary_images_real[dataset_index]),len(loaded_dictionary_images_sim[dataset_index]))):\n",
    "    test_dataset_indices_inner.append(index)\n",
    "\n",
    "pattern = 'tttttttttt'\n",
    "pattern_pointer = 0\n",
    "for index in range(0, min(len(loaded_dictionary_images_real_train[dataset_index]),len(loaded_dictionary_images_sim_train[dataset_index]))):\n",
    "    train_dataset_indices_inner.append(index)\n",
    "\n",
    "\n",
    "train_indexes_gan[dataset_index]=train_dataset_indices_inner\n",
    "test_indexes_gan[dataset_index]=test_dataset_indices_inner\n",
    "\n",
    "print(\"GAN train and test\")\n",
    "print(\"Dataset\", dataset_index)\n",
    "print(\"Train: \",len(train_indexes_gan[dataset_index]))\n",
    "print(\"Test: \",len(test_indexes_gan[dataset_index]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad2ac77-1937-4155-af0f-277edafba429",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset_index)\n",
    "for i in range(0, 10):\n",
    "  # Create a 2x2 grid of subplots\n",
    "  fig, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
    "  plt.subplots_adjust(wspace=0.2, hspace=0.4)\n",
    "\n",
    "  # Plot the real and fake images side by side in the first row\n",
    "  axs[0].imshow(cv2.cvtColor(loaded_dictionary_images_real[dataset_index][i], cv2.COLOR_BGR2RGB))\n",
    "  axs[0].set_title(str(loaded_dictionary_gt_real[dataset_index][i]))\n",
    "  axs[1].imshow(cv2.cvtColor(loaded_dictionary_images_sim[dataset_index][i], cv2.COLOR_BGR2RGB))\n",
    "  axs[1].set_title(str(loaded_dictionary_gt_sim[dataset_index][i]))\n",
    "\n",
    "  for ax in axs.flat:\n",
    "      ax.set_xticks([])\n",
    "      ax.set_yticks([])\n",
    "\n",
    "  # Show the plot for the current iteration\n",
    "  plt.show()\n",
    "\n",
    "print(dataset_index)\n",
    "for i in range(0, 10):\n",
    "  # Create a 2x2 grid of subplots\n",
    "  fig, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
    "  plt.subplots_adjust(wspace=0.2, hspace=0.4)\n",
    "\n",
    "  # Plot the real and fake images side by side in the first row\n",
    "  axs[0].imshow(cv2.cvtColor(loaded_dictionary_images_real_train[dataset_index][i], cv2.COLOR_BGR2RGB))\n",
    "  axs[0].set_title(str(loaded_dictionary_gt_real_train[dataset_index][i]))\n",
    "  axs[1].imshow(cv2.cvtColor(loaded_dictionary_images_sim_train[dataset_index][i], cv2.COLOR_BGR2RGB))\n",
    "  axs[1].set_title(str(loaded_dictionary_gt_sim_train[dataset_index][i]))\n",
    "\n",
    "  for ax in axs.flat:\n",
    "      ax.set_xticks([])\n",
    "      ax.set_yticks([])\n",
    "\n",
    "  # Show the plot for the current iteration\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e399300e-4606-4698-b597-aa0ef4552626",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3f3fbe-afcd-4aea-97e6-a51b01aa9b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(loaded_dictionary_images_real[dataset_index]))\n",
    "print(len(loaded_dictionary_images_sim[dataset_index]))\n",
    "print(len(loaded_dictionary_gt_real[dataset_index]))\n",
    "print(len(loaded_dictionary_gt_sim[dataset_index]))\n",
    "\n",
    "print(len(loaded_dictionary_images_real_train[dataset_index]))\n",
    "print(len(loaded_dictionary_images_sim_train[dataset_index]))\n",
    "print(len(loaded_dictionary_gt_real_train[dataset_index]))\n",
    "print(len(loaded_dictionary_gt_sim_train[dataset_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ffe4bc6-f4cc-4f03-afad-b8fe36223c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_sim_real_outputs(real_path,sim_path):\n",
    "        dataset_index=\"0001\"\n",
    "        print(dataset_index)\n",
    "        counter=0\n",
    "        for i in range(0,len(loaded_dictionary_images_sim[dataset_index])):\n",
    "                counter+=1\n",
    "                input_image_sim = np.array(loaded_dictionary_images_sim[dataset_index][i])\n",
    "                input_image_sim = tf.convert_to_tensor(input_image_sim.astype(np.uint8), np.uint8)\n",
    "                input_image_sim = tf.reverse(input_image_sim, axis=[-1])\n",
    "                png_image = tf.image.encode_png(input_image_sim)\n",
    "                os.makedirs('./content/datasets/processed_data_testing/'+sim_path+'/', exist_ok=True)\n",
    "                with open('./content/datasets/processed_data_testing/'+sim_path+'/'+str(dataset_index)+'_'+str(i)+'.png', 'wb') as f:\n",
    "                  f.write(png_image.numpy())\n",
    "        counter=0\n",
    "        for i in range(0,len(loaded_dictionary_images_real[dataset_index])):\n",
    "                counter+=1\n",
    "                input_image_real = np.array(loaded_dictionary_images_real[dataset_index][i])\n",
    "                input_image_real = tf.convert_to_tensor(input_image_real.astype(np.uint8), np.uint8)\n",
    "                input_image_real = tf.reverse(input_image_real, axis=[-1])\n",
    "                \n",
    "                png_image = tf.image.encode_png(input_image_real)\n",
    "                os.makedirs('./content/datasets/processed_data_testing/'+real_path+'/', exist_ok=True)\n",
    "                with open('./content/datasets/processed_data_testing/'+real_path+'/'+str(dataset_index)+'_'+str(i)+'.png', 'wb') as f:\n",
    "                  f.write(png_image.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b686163-f7f4-4c83-8786-4b710482874b",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_sim_real_outputs(\"real\",\"sim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a1e22f-641b-4848-ac75-b0fd91c13aec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e36f46-1523-420f-84b2-b399c2e630bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff41fe9-39ed-4c9e-942d-5589a0d00801",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670f64a2-8080-4fd0-b1b4-f9e5e6a5b726",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a8cdbb-dbef-48e2-8ad2-da9615de1113",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5cf4d7-9aec-4584-8dc0-ddb7e3c29da5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c44d89-92fb-4ab9-bba4-8c4038f585cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3536d4-3bff-4704-a9ae-8e2055a4b813",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce319727-486a-492c-a27b-57849bb0833c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f78ca43-8cd1-4434-8195-8cb4825d44a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917da750-7d3a-487b-b8a0-49b7df2df021",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7256cf56-ace9-46fa-83b6-4a5df54f292e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f522f1-987f-45a3-a27c-a3f476a6a9b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4b2276-87be-4260-973f-1b155ea314df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b904ab8-35fa-4f39-8ab5-3155859da904",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc629af-6d6f-4156-b523-62add660e6f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9790c9a4-88e7-4408-9009-999e0d4f992b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfEnv4",
   "language": "python",
   "name": "tfenv4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
