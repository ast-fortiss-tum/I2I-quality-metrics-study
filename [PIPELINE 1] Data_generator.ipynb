{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb0be94a",
   "metadata": {},
   "source": [
    "# Data generator\n",
    "This notebook uses the simulated and real datasets to produce the generated images using 3 pix2pix and 3 CycleGAN networks.\n",
    "It aslo produces the segmentation masks using Segformer.\n",
    "\n",
    "## Usage:\n",
    "### task_type='donkey' <- Choose task domain 'donkey' or 'kitti' for lane-keeping or vehicle detection\n",
    "Run all cells\n",
    "\n",
    "## Requirements:\n",
    "-Segformer checkpoints for segmentation: \\\n",
    "    ./[task_type]/content/segmentation_checkpoints/Model_weights.hdf5 \\\n",
    "    \n",
    "    Please refer to specific [task_type] to generate segmentation checkpoint\n",
    "\n",
    "-CycleGAN and pix2pix checkpoints for I2I translation:\\\n",
    "    ./[task_type]/content/gan_checkpoints/cyclegan_checkpoints/1/ \\\n",
    "    ./[task_type]/content/gan_checkpoints/cyclegan_checkpoints/2/ \\\n",
    "    ./[task_type]/content/gan_checkpoints/cyclegan_checkpoints/3/ \\\n",
    "    ./[task_type]/content/gan_checkpoints/pix2pix_checkpoints/1/ \\\n",
    "    ./[task_type]/content/gan_checkpoints/pix2pix_checkpoints/2/ \\\n",
    "    ./[task_type]/content/gan_checkpoints/pix2pix_checkpoints/3/ \n",
    "\n",
    "    Please refer to specific [task_type] to generate GAN checkpoints\n",
    "\n",
    "-Dataset h5 files: \\\n",
    "    KITTI: \\\n",
    "    ./[task_type]/content/datasets/h5_out/bounding_boxes_real.h5\\\n",
    "    ./[task_type]/content/datasets/h5_out/bounding_boxes_sim.h5\\\n",
    "    ./[task_type]/content/datasets/h5_out/raw_image_real.h5\\\n",
    "    ./[task_type]/content/datasets/h5_out/raw_image_sim.h5\\\n",
    "    ./[task_type]/content/datasets/h5_out/segmentation_masks_real.h5\\\n",
    "    ./[task_type]/content/datasets/h5_out/segmentation_masks_sim.h5\\\n",
    "    ./[task_type]/content/datasets/h5_out/semantic_id_list_real.h5\\\n",
    "    ./[task_type]/content/datasets/h5_out/semantic_id_list_sim.h5\\\n",
    "    DONKEY:\\\n",
    "    ./[task_type]/content/datasets/h5_out/gt_real.h5\\\n",
    "    ./[task_type]/content/datasets/h5_out/raw_image_real.h5\\\n",
    "    ./[task_type]/content/datasets/h5_out/raw_image_sim.h5\\\n",
    "    ./[task_type]/content/datasets/h5_out/semantic_id_list_real.h5\\\n",
    "    ./[task_type]/content/datasets/h5_out/semantic_id_list_sim.h5\\\n",
    "\n",
    "    Please refer to specific [task_type] to generate h5 files\n",
    "\n",
    "## Outputs:\n",
    "    ./[task_type]/content/output_plots/[domain_type]/[domain_type] \n",
    "    ./[task_type]/content/output_plots/[domain_type]/[domain_type]_mask \n",
    "    ./[task_type]/content/output_plots/[domain_type]/[domain_type]_additional_mask \n",
    "    ./[task_type]/content/output_plots/[domain_type]/[domain_type]_mask_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c671b3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import tensorflow as tf\n",
    "from tensorflow_examples.models.pix2pix import pix2pix\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import data_generator_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f09ca4",
   "metadata": {},
   "source": [
    "## Set parameters and task type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea338ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_CHANNELS = 3\n",
    "BUFFER_SIZE = 1000\n",
    "BATCH_SIZE = 1\n",
    "IMG_WIDTH = 512\n",
    "IMG_HEIGHT = 512\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "task_type='donkey'\n",
    "output_folder = './'+task_type+'/content/output_plots'\n",
    "plot=False\n",
    "two_classes=False\n",
    "limit=10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b390bfd",
   "metadata": {},
   "source": [
    "## Load necessary data and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2722ada9-b82d-4e38-88b8-ff74a0c34f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './'+task_type+'/content/datasets/h5_out/raw_image_sim.h5'\n",
    "loaded_dictionary_images_sim=data_generator_utils.load_h5_to_dictionary(file_path)\n",
    "file_path = './'+task_type+'/content/datasets/h5_out/raw_image_real.h5'\n",
    "loaded_dictionary_images_real=data_generator_utils.load_h5_to_dictionary(file_path)\n",
    "file_path = './'+task_type+'/content/datasets/h5_out/semantic_id_list_real.h5'\n",
    "loaded_semantic_id_real=data_generator_utils.load_h5_to_dictionary(file_path)\n",
    "file_path = './'+task_type+'/content/datasets/h5_out/semantic_id_list_sim.h5'\n",
    "loaded_semantic_id_sim=data_generator_utils.load_h5_to_dictionary(file_path)\n",
    "\n",
    "if task_type==\"kitti\":\n",
    "    file_path = './'+task_type+'/content/datasets/h5_out/bounding_boxes_sim.h5'\n",
    "    loaded_bounding_sim=data_generator_utils.load_h5_to_dictionary(file_path)\n",
    "    file_path = './'+task_type+'/content/datasets/h5_out/bounding_boxes_real.h5'\n",
    "    loaded_bounding_real=data_generator_utils.load_h5_to_dictionary(file_path)\n",
    "    height,width=374,1238\n",
    "    road=0\n",
    "    additional_id=3\n",
    "    additional_id_init=13\n",
    "    dataset_index_list_test=[\"0001\",\"0002\",\"0006\",\"0018\",\"0020\"]\n",
    "    pattern = 'tvvttvttnn'\n",
    "    \n",
    "elif task_type==\"donkey\":\n",
    "    height,width=140,320\n",
    "    road=1\n",
    "    additional_id=1\n",
    "    additional_id_init=2\n",
    "    dataset_index_list_test=[\"0001\"]\n",
    "    pattern = 'vvvvvvvvvv'\n",
    "    \n",
    "else:\n",
    "    print(\"Choose a set\")\n",
    "\n",
    "\n",
    "train_indexes_gan,test_indexes_gan=data_generator_utils.get_gan_indexes(dataset_index_list_test,loaded_dictionary_images_real,loaded_dictionary_images_sim,pattern)\n",
    "loaded_dictionary_images_real,loaded_dictionary_images_sim,loaded_semantic_id_real,loaded_semantic_id_sim=data_generator_utils.crop_data_dictionaries(task_type,dataset_index_list_test,loaded_dictionary_images_real,loaded_dictionary_images_sim,loaded_semantic_id_real,loaded_semantic_id_sim)\n",
    "\n",
    "checkpoint_file_path = \"./\"+task_type+\"/content/segmentation_checkpoints/Model_weights.hdf5\"\n",
    "segmentation_model=data_generator_utils.load_segmentation_model(checkpoint_file_path,task_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d218f1c",
   "metadata": {},
   "source": [
    "## Generate sim and real data\n",
    "- Generate and populate sim and real image folders ('/content/output_plots/sim/sim and '/content/output_plots/real/real)\n",
    "- Compute and populate semantic masks folders ('/content/output_plots/sim/sim_mask' and '/content/output_plots/real/real_mask')\n",
    "- Compute and populate TSS and OC-TSS metric folders (reffered as semantic mask error in the codebase: '/content/output_plots/sim/sim_mask_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b686163-f7f4-4c83-8786-4b710482874b",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_path_name=\"real\"\n",
    "sim_path_name=\"sim\"\n",
    "data_generator_utils.save_sim_real_outputs(task_type,segmentation_model,real_path_name,sim_path_name,additional_id,height,width,dataset_index_list_test,test_indexes_gan,loaded_dictionary_images_real,loaded_dictionary_images_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081a8661",
   "metadata": {},
   "source": [
    "## Generate CycleGAN data\n",
    "- Generate and populate image folders ('/content/output_plots/cyclegan/cyclegan_id) for each cyclegan_id in checkpoint_names\n",
    "- Compute and populate semantic masks folders ('/content/output_plots/cyclegan/cyclegan_id_mask')  for each cyclegan_id in checkpoint_names\n",
    "- Compute and populate TSS and OC-TSS metric folders (reffered as semantic mask error in the codebase: '/content/output_plots/cyclegan/cyclegan_id_mask_error')  for each cyclegan_id in checkpoint_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d85621-671e-4bf4-a358-4522bda44ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_paths = ['./'+task_type+'/content/gan_checkpoints/cyclegan_checkpoints/1','./'+task_type+'/content/gan_checkpoints/cyclegan_checkpoints/2','./'+task_type+'/content/gan_checkpoints/cyclegan_checkpoints/3']\n",
    "checkpoint_names=[\"cyclegan_1\",\"cyclegan_2\",\"cyclegan_3\"]\n",
    "\n",
    "for checkpoint_path,checkpoint_name in zip(checkpoint_paths,checkpoint_names):\n",
    "    print(checkpoint_path)\n",
    "    generator_cyclegan = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')\n",
    "    ckpt_cyclegan = tf.train.Checkpoint(generator_g=generator_cyclegan)\n",
    "    ckpt_manager_cyclegan = tf.train.CheckpointManager(ckpt_cyclegan, checkpoint_path, max_to_keep=5)\n",
    "    if ckpt_manager_cyclegan.latest_checkpoint:\n",
    "        ckpt_cyclegan.restore(ckpt_manager_cyclegan.latest_checkpoint)\n",
    "        print ('Checkpoint restored')\n",
    "    else:\n",
    "        print ('No Checkpoint! Check source path')\n",
    "    print(height,width)\n",
    "    data_generator_utils.save_cyclegan_outputs(task_type,segmentation_model,generator_cyclegan,checkpoint_name,additional_id,height,width,dataset_index_list_test,test_indexes_gan,loaded_dictionary_images_real,loaded_dictionary_images_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e97ead",
   "metadata": {},
   "source": [
    "## Generate pix2pix data\n",
    "- Generate and populate image folders ('/content/output_plots/pix2pix/pix2pix_id) for each pix2pix_id in checkpoint_names\n",
    "- Compute and populate semantic masks folders ('/content/output_plots/pix2pix/pix2pix_id_mask')  for each pix2pix_id in checkpoint_names\n",
    "- Compute and populate TSS and OC-TSS metric folders (reffered as semantic mask error in the codebase: '/content/output_plots/pix2pix/pix2pix_id_mask_error')  for each pix2pix_id in checkpoint_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a980103a-3925-4145-ba89-2a15b1b0a9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_paths = ['./'+task_type+'/content/gan_checkpoints/pix2pix_checkpoints/1','./'+task_type+'/content/gan_checkpoints/pix2pix_checkpoints/2','./'+task_type+'/content/gan_checkpoints/pix2pix_checkpoints/3']\n",
    "checkpoint_names=[\"pix2pix_mask_1\",\"pix2pix_mask_2\",\"pix2pix_mask_3\"]\n",
    "    \n",
    "\n",
    "input_domain=\"sim\"\n",
    "pix2pix_mask_type=\"manual\"\n",
    "\n",
    "for checkpoint_path,checkpoint_name in zip(checkpoint_paths,checkpoint_names):\n",
    "    generator_pix2pix_mask_real = data_generator_utils.Generator()\n",
    "    ckpt_pix2pix_mask_real = tf.train.Checkpoint(\n",
    "                                     generator=generator_pix2pix_mask_real)\n",
    "    ckpt_manager_pix2pix_mask_real = tf.train.CheckpointManager(ckpt_pix2pix_mask_real, checkpoint_path, max_to_keep=5)\n",
    "    if ckpt_manager_pix2pix_mask_real.latest_checkpoint:\n",
    "        ckpt_pix2pix_mask_real.restore(ckpt_manager_pix2pix_mask_real.latest_checkpoint)\n",
    "        print ('Checkpoint restored')\n",
    "    else:\n",
    "        print ('No Checkpoint! Check source path')\n",
    "    data_generator_utils.save_pix2pix_mask_outputs(task_type,limit,segmentation_model,two_classes,generator_pix2pix_mask_real,checkpoint_name,additional_id,height,width,input_domain,pix2pix_mask_type,dataset_index_list_test, test_indexes_gan, loaded_dictionary_images_real,loaded_dictionary_images_sim,loaded_semantic_id_real,loaded_semantic_id_sim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfEnv4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
