{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c36bc1aa",
   "metadata": {},
   "source": [
    "# Image metrics generator\n",
    "This notebook uses the images folders generated using [PIPELINE 1] and produces the image metric values for each image.\n",
    "\n",
    "## Usage:\n",
    "Run all cells\n",
    "\n",
    "## Requirements:\n",
    "-Image folders:\\\n",
    "    ./[task_type]/content/output_plots/[domain_type]/[domain_type]\n",
    "\n",
    "## Outputs:\n",
    "    ./[task_type]/content/output_plots/[domain_type]/[domain_type]_metrics_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b463868d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import image_metrics_utils\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7fb00d",
   "metadata": {},
   "source": [
    "### Calculate image metric scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ffbacdf-dc1c-45f2-a33f-207f4fae8b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_scores(type,model_type,source_name):\n",
    "\n",
    "    folder1_path = './'+type+'/content/output_plots/real/real/'\n",
    "    folder2_path = './'+type+'/content/output_plots/'+model_type+'/'+str(source_name)+'/'\n",
    "    os.makedirs('./'+type+'/content/output_plots/'+model_type+'/'+str(source_name)+'_metrics_results/', exist_ok=True)\n",
    "    output_folder = './'+type+'/content/output_plots/'+model_type+'/'+str(source_name)+'_metrics_results/'\n",
    "    \n",
    "    # Load images from folders\n",
    "    images1,_ = image_metrics_utils.load_images_from_folder(folder1_path)\n",
    "    images2,path2 = image_metrics_utils.load_images_from_folder(folder2_path)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    results = []\n",
    "    results_dict = {}\n",
    "\n",
    "\n",
    "    print(type,model_type,source_name)\n",
    "    \n",
    "    print(\"Calculating SSIM scores...\")\n",
    "    ssim_scores = [image_metrics_utils.calculate_ssim(img1, img2) for img1, img2 in zip(images1, images2)]\n",
    "    results.append(ssim_scores)\n",
    "    results_dict[\"ssim_scores\"]=ssim_scores\n",
    "    \n",
    "    print(\"Calculating PSNR scores...\")\n",
    "    psnr_scores = [image_metrics_utils.calculate_psnr(img1, img2) for img1, img2 in zip(images1, images2)]\n",
    "    results.append(psnr_scores)\n",
    "    results_dict[\"psnr_scores\"]=psnr_scores\n",
    "    \n",
    "    print(\"Calculating MSE scores...\")\n",
    "    mse_scores = [image_metrics_utils.calculate_mse(img1, img2) for img1, img2 in zip(images1, images2)]\n",
    "    results.append(mse_scores)\n",
    "    results_dict[\"mse_scores\"]=mse_scores\n",
    "    \n",
    "    print(\"Calculating cosine similarities...\")\n",
    "    cosine_similarities = image_metrics_utils.calculate_cosine_similarity(images1, images2)\n",
    "    results.append(cosine_similarities)\n",
    "    results_dict[\"cosine_similarities\"]=cosine_similarities\n",
    "    \n",
    "    print(\"Calculating correlation coefficients...\")\n",
    "    corr_coeffs = [image_metrics_utils.calculate_correlation_coefficient(img1, img2) for img1, img2 in zip(images1, images2)]\n",
    "    results.append(corr_coeffs)\n",
    "    results_dict[\"corr_coeffs\"]=corr_coeffs\n",
    "    \n",
    "    print(\"Calculating Texture Similarity...\")\n",
    "    text_sim=image_metrics_utils.calculate_texture_similarity(images1, images2)\n",
    "    results.append(text_sim)\n",
    "    results_dict[\"text_sim\"]=text_sim\n",
    "    \n",
    "    print(\"Calculating WD Score...\")\n",
    "    wd_score=image_metrics_utils.calculate_wd(images1, images2)\n",
    "    results.append(wd_score)\n",
    "    results_dict[\"wd_score\"]=wd_score\n",
    "    \n",
    "    print(\"Calculating KL Divergence...\")\n",
    "    kl_div=image_metrics_utils.calculate_kl_divergence(images1, images2)\n",
    "    results.append(kl_div)\n",
    "    results_dict[\"kl_div\"]=kl_div\n",
    "    \n",
    "    print(\"Calculating Histogram Intersection...\")\n",
    "    hist_inter=image_metrics_utils.calculate_histogram_intersection(images1, images2)\n",
    "    results.append(hist_inter)\n",
    "    results_dict[\"hist_inter\"]=hist_inter\n",
    "    \n",
    "    print(\"Calculating Perceptual Dist...\")\n",
    "    perc_dist= image_metrics_utils.calculate_perceptual_distances(images1, images2)\n",
    "    results.append(perc_dist)\n",
    "    results_dict[\"perc_dist\"]=perc_dist\n",
    "\n",
    "    print(\"Calculating Inception Score...\")\n",
    "    inception_score = image_metrics_utils.calculate_inception_score(images1,images2)\n",
    "    results_dict[\"inception_score\"] = inception_score\n",
    "    print(results_dict[\"inception_score\"])\n",
    "    \n",
    "    \n",
    "    print(\"Calculating FID...\")\n",
    "    fid_score = image_metrics_utils.calculate_fid(images1, images2)\n",
    "    results_dict[\"fid_score\"] = fid_score\n",
    "\n",
    "    print(\"Calculating Kernel Density Estimation (KDE)...\")\n",
    "    kde_scores, kde_probs = image_metrics_utils.calculate_kde(images2)\n",
    "    results.append(kde_scores)\n",
    "    results_dict[\"kde_scores\"] = kde_scores\n",
    "    results.append(kde_probs)\n",
    "    results_dict[\"kde_probs\"] = kde_probs\n",
    "\n",
    "    if type=='donkey':\n",
    "        print(\"Calculating Kernel Inception Distance (KID)...\")\n",
    "        kid_score = image_metrics_utils.calculate_kid_donkey(images1, images2)\n",
    "        results_dict[\"kid_score\"] = kid_score.numpy()\n",
    "    else:\n",
    "        print(\"Calculating Kernel Inception Distance (KID)...\")\n",
    "        kid_score = image_metrics_utils.calculate_kid_kitti(images1, images2)\n",
    "        results_dict[\"kid_score\"] = kid_score.numpy()\n",
    "    \n",
    "\n",
    "    print(\"Calculating Semantic seg score (SSS)...\")\n",
    "    sss = image_metrics_utils.calculate_semantic_segmentation_score(images1, images2)\n",
    "    results_dict[\"ss_score\"]=sss\n",
    "    \n",
    "    \n",
    "    print(\"Saving jsons for \"+source_name)\n",
    "    for i in range(0,len(path2)):\n",
    "        single_results_dict = {}\n",
    "        for metric_name in results_dict:\n",
    "            if (metric_name == metric_name == 'inception_score' or metric_name==\"kid_score\" or metric_name==\"fid_score\"):\n",
    "                # print(metric_name)\n",
    "                single_results_dict[metric_name] = float(results_dict[metric_name])\n",
    "            else:\n",
    "                # print(metric_name)\n",
    "                single_results_dict[metric_name] = float(results_dict[metric_name][i])\n",
    "        output_name=output_folder+path2[i].split(\"/\")[-1].split(\"_\")[0]+\"_\"+path2[i].split(\"/\")[-1].split(\"_\")[1].split(\".\")[0]+\".json\"\n",
    "        with open(output_name, \"w\") as json_file:\n",
    "            json.dump(single_results_dict, json_file)\n",
    "    \n",
    "    print(\"Results saved as JSON.\")\n",
    "    return results_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6b4d7e",
   "metadata": {},
   "source": [
    "### Calculate image metrics for kitti domain type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2757da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_type='kitti'\n",
    "model_type,source_name='sim','sim'\n",
    "calculate_scores(task_type,model_type,source_name)\n",
    "model_type='cyclegan'\n",
    "source_names=['cyclegan_1','cyclegan_2','cyclegan_3']\n",
    "for source_name in source_names:\n",
    "    calculate_scores(task_type,model_type,source_name)\n",
    "model_type='pix2pix_mask_manual'\n",
    "source_names=['pix2pix_mask_1_sim','pix2pix_mask_2_sim','pix2pix_mask_3_sim']\n",
    "for source_name in source_names:\n",
    "    calculate_scores(task_type,model_type,source_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2509de1",
   "metadata": {},
   "source": [
    "### Calculate image metrics for donkey domain type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38246cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_type='donkey'\n",
    "model_type,source_name='sim','sim'\n",
    "calculate_scores(task_type,model_type,source_name)\n",
    "model_type='cyclegan'\n",
    "source_names=['cyclegan_1','cyclegan_2','cyclegan_3']\n",
    "for source_name in source_names:\n",
    "    calculate_scores(task_type,model_type,source_name)\n",
    "model_type='pix2pix_mask_manual'\n",
    "source_names=['pix2pix_mask_1_sim','pix2pix_mask_2_sim','pix2pix_mask_3_sim']\n",
    "for source_name in source_names:\n",
    "    calculate_scores(task_type,model_type,source_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfEnv4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
