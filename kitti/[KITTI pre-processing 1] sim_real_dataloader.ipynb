{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data generator KITTI\n",
    "This notebook uses the simulated and real data to produce the .pkl and .h5 files for I2I models training, segmentation training, and image generation.\n",
    "\n",
    "## Usage:\n",
    "Run all cells\n",
    "\n",
    "## Requirements:\n",
    "./content/datasets/data_in/objects/ must contain folders /sim/ & /real/ each with the img, obj, and segm data from KITTI and VKITTI datasets.\n",
    "\n",
    "## Outputs:\n",
    "./content/datasets/h5_out/bounding_boxes_real.h5\\\n",
    "./content/datasets/h5_out/bounding_boxes_sim.h5\\\n",
    "./content/datasets/h5_out/raw_image_real.h5\\\n",
    "./content/datasets/h5_out/raw_image_sim.h5\\\n",
    "./content/datasets/h5_out/segmentation_masks_real.h5\\\n",
    "./content/datasets/h5_out/segmentation_masks_sim.h5\\\n",
    "./content/datasets/h5_out/semantic_id_list_real.h5\\\n",
    "./content/datasets/h5_out/semantic_id_list_sim.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image as Image\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL.Image as Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q6Y9_zrr1tO2",
    "outputId": "7eea9c3f-bbf4-4500-d8d8-dda1cdcdc6a9"
   },
   "outputs": [],
   "source": [
    "img = np.array(Image.open(\"./content/datasets/data_in/objects/real/segm/0000/000000.png\"))\n",
    "obj_ids = np.unique(img)\n",
    "obj_id = obj_ids[0]\n",
    "class_id = obj_id // 1000\n",
    "obj_instance_id = obj_id % 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "nwtGb34m48xG"
   },
   "outputs": [],
   "source": [
    "\n",
    "def map_to_r(number):\n",
    "    colorr = [255, 128, 0, 0, 128, 0, 0, 0, 128, 0, 0, 0, 128, 0, 128, 255, 128, 255, 0, 128]\n",
    "    if number < 20:\n",
    "        return int(colorr[number])\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def map_to_g(number):\n",
    "    colorg = [0, 128, 255, 128, 0, 0, 128, 0, 0, 128, 0, 128, 0, 128, 255, 128, 0, 128, 255, 128]\n",
    "    if number < 20:\n",
    "        return int(colorg[number])\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def map_to_b(number):\n",
    "    colorb = [0, 0, 0, 128, 128, 255, 255, 128, 0, 128, 128, 255, 128, 0, 0, 0, 128, 255, 255, 128]\n",
    "    if number < 20:\n",
    "        return int(colorb[number])\n",
    "    else:\n",
    "        return 255\n",
    "\n",
    "\n",
    "def load_real_data(dataset_index,visualize=False,stop=0,color_map=False):\n",
    "  # Update the paths to the dataset folders accordingly\n",
    "  images_folder = f\"./content/datasets/data_in/objects/real/img/{dataset_index}\"\n",
    "  labels_file = f\"./content/datasets/data_in/objects/real/obj/{dataset_index}.txt\"\n",
    "  segmentation_masks_folder = f\"./content/datasets/data_in/objects/real/segm/{dataset_index}\"\n",
    "\n",
    "  images_list_index_real=[]\n",
    "  images_list_real=[]\n",
    "  segmentation_masks_list_real=[]\n",
    "  semantic_id_list_real=[]\n",
    "  bounding_boxes_list_real=[]\n",
    "  raw_image_real=[]\n",
    "\n",
    "\n",
    "\n",
    "  # Read the ground truth labels from the text file\n",
    "  with open(labels_file, 'r') as f:\n",
    "      lines = f.readlines()\n",
    "\n",
    "  # Dictionary to store bounding boxes or labels for each image index\n",
    "  ground_truth_data = {}\n",
    "  # Process ground truth lines and group them by image index\n",
    "  image_files = sorted(os.listdir(images_folder))\n",
    "  max_index=int(image_files[-1].strip().split('.png')[0])\n",
    "  for index in range(0,max_index+1):\n",
    "    if index not in ground_truth_data:\n",
    "                  ground_truth_data[index] = []\n",
    "\n",
    "\n",
    "  for line in lines:\n",
    "\n",
    "      line_parts = line.strip().split(' ')\n",
    "      image_index = int(line_parts[0])\n",
    "      if(image_index<=stop or stop==0):\n",
    "          label = line_parts[2]\n",
    "\n",
    "          if label != 'DontCare':\n",
    "              x_min = int(float(line_parts[6]))\n",
    "              y_min = int(float(line_parts[7]))\n",
    "              x_max = int(float(line_parts[8]))\n",
    "              y_max = int(float(line_parts[9]))\n",
    "\n",
    "              # Save bounding box or label in the dictionary\n",
    "              ground_truth_data[image_index].append((label, x_min, y_min, x_max, y_max))\n",
    "\n",
    "  # Step 4: Load segmentation masks and overlay them on the images\n",
    "\n",
    "  # Sort the image indices in ascending order\n",
    "  sorted_image_indices = sorted(ground_truth_data.keys())\n",
    "\n",
    "\n",
    "  # Process images in the sorted order\n",
    "  for image_index in sorted_image_indices:\n",
    "      if(image_index%50==0):\n",
    "        print(image_index)\n",
    "      # Load the image\n",
    "      image_file = sorted(os.listdir(images_folder))[image_index]\n",
    "      image_path = os.path.join(images_folder, image_file)\n",
    "      image = cv2.imread(image_path)\n",
    "      raw_image_real.append(image)\n",
    "      # Get bounding boxes or labels for the current image index\n",
    "      bounding_boxes = ground_truth_data[image_index]\n",
    "      image2 = image.copy()\n",
    "\n",
    "      # Draw bounding boxes or labels on the image\n",
    "      for label, x_min, y_min, x_max, y_max in bounding_boxes:\n",
    "          if x_max > x_min and y_max > y_min:\n",
    "              cv2.rectangle(image2, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
    "              cv2.putText(image2, label, (x_min, y_min - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "              bounding_boxes_list_real.append((image_index,label, x_min, y_min, x_max, y_max))\n",
    "\n",
    "      # Load the segmentation mask and overlay it on the image\n",
    "      segmentation_mask_file = f\"{os.path.splitext(image_file)[0]}.png\"\n",
    "      segmentation_mask_path = os.path.join(segmentation_masks_folder, segmentation_mask_file)\n",
    "      if os.path.exists(segmentation_mask_path):\n",
    "          segmentation_mask = cv2.imread(segmentation_mask_path)\n",
    "          semantic_id = segmentation_mask[:, :, 2]  # Red channel contains semantic_id\n",
    "          instance_id = segmentation_mask[:, :, 1] * 256 + segmentation_mask[:, :, 0]  # Green and Blue channels contain instance_id\n",
    "          unique=np.unique(semantic_id)\n",
    "          semantic_id[semantic_id == 3] = 2\n",
    "          semantic_id[semantic_id == 9] = 8\n",
    "          semantic_id[semantic_id == 4] = 2\n",
    "          semantic_id[semantic_id == 5] = 2\n",
    "\n",
    "          if(color_map):\n",
    "            colored_mask = np.zeros_like(image)\n",
    "            colored_mask[:, :, 0] = np.vectorize(map_to_b)(semantic_id)\n",
    "            colored_mask[:, :, 1] = np.vectorize(map_to_g)(semantic_id)\n",
    "            colored_mask[:, :, 2] = np.vectorize(map_to_r)(semantic_id)\n",
    "            segmentation_masks_list_real.append(colored_mask)\n",
    "            if(visualize):\n",
    "              overlay = cv2.addWeighted(image, 0.7, colored_mask, 0.3, 0)\n",
    "              plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "              plt.show()\n",
    "              plt.imshow(cv2.cvtColor(colored_mask, cv2.COLOR_BGR2RGB))\n",
    "              plt.show()\n",
    "              plt.imshow(cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB))\n",
    "              plt.show()\n",
    "\n",
    "          images_list_index_real.append(image_index)\n",
    "          images_list_real.append(image2)\n",
    "          semantic_id_list_real.append(semantic_id)\n",
    "  return images_list_index_real,images_list_real,segmentation_masks_list_real,semantic_id_list_real,bounding_boxes_list_real,raw_image_real\n",
    "\n",
    "\n",
    "def parse_txt_file(txt_file):\n",
    "    color_to_class_id = {}\n",
    "    with open(txt_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines[1:]:  # Skip the header line\n",
    "            parts = line.strip().split()\n",
    "            class_name = parts[0]\n",
    "            # If the class_name starts with \"Car:\", change it to just \"Car\"\n",
    "            rgb_values = tuple(map(int, parts[1:]))\n",
    "            color_to_class_id[rgb_values] = class_name\n",
    "    return color_to_class_id\n",
    "\n",
    "def rgb_mask_to_class_ids(rgb_mask, class_to_id, label_id_mapping):\n",
    "\n",
    "    # Create a lookup table for faster mapping\n",
    "    lookup_table = np.zeros((256, 256, 256), dtype=np.uint8)\n",
    "    for rgb_pixel, class_name in class_to_id.items():\n",
    "        if class_name.startswith(\"Car\") or class_name.startswith(\"Van\"):\n",
    "            class_name = \"Car\"\n",
    "        lookup_table[rgb_pixel] = label_id_mapping[class_name]\n",
    "\n",
    "    # Convert the RGB mask to a 1D array of unique colors\n",
    "    flat_rgb_mask = rgb_mask.reshape(-1, 3)\n",
    "\n",
    "    # Use the lookup table to map the colors to class IDs\n",
    "    class_ids = lookup_table[flat_rgb_mask[:, 0], flat_rgb_mask[:, 1], flat_rgb_mask[:, 2]]\n",
    "\n",
    "    # Reshape the class IDs back to the original image shape\n",
    "    class_ids = class_ids.reshape(rgb_mask.shape[:2])\n",
    "\n",
    "    return class_ids\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def interpolate_color(index, unique):\n",
    "    r = int(index * (255 / unique))\n",
    "    g = int((unique - index) * (255 / unique))\n",
    "    b = 128  # Set a constant value for blue (change this value for a different shade of blue)\n",
    "    return r, g, b\n",
    "\n",
    "\n",
    "\n",
    "def load_sim_data(dataset_index,visualize=False,stop=0,color_map=False):\n",
    "  images_list_sim = []\n",
    "  bounding_boxes_list_sim = []\n",
    "  segmentation_masks_list_sim = []\n",
    "  images_list_index_sim = []\n",
    "  semantic_id_list_sim = []\n",
    "  raw_image_sim = []\n",
    "\n",
    "  label_id_mapping = {\n",
    "        'Road': 0,\n",
    "        'Sidewalk': 1,\n",
    "        'Building': 2,\n",
    "        'Wall': 2,\n",
    "        'Fence': 2,\n",
    "        'Pole': 2,\n",
    "        'TrafficLight': 6,\n",
    "        'TrafficSign': 7,\n",
    "        'Vegetation': 8,\n",
    "        'Tree': 8,\n",
    "        'Terrain': 1,\n",
    "        'Sky': 10,\n",
    "        'Person': 11,\n",
    "        'Rider': 12,\n",
    "        'Car': 13,\n",
    "        'Truck': 14,\n",
    "        'Bus': 15,\n",
    "        'Train': 16,\n",
    "        'Motorcycle': 17,\n",
    "        'Bicycle': 18,\n",
    "        'Void': 255,\n",
    "        'Misc': 2,\n",
    "        'GuardRail': 21,\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  # Update the paths to the dataset folders accordingly\n",
    "  images_folder = f\"./content/datasets/data_in/objects/sim/img/{dataset_index}/clone\"\n",
    "  labels_file = f\"./content/datasets/data_in/objects/sim/obj/{dataset_index}_clone.txt\"\n",
    "  segmentation_masks_folder = f\"./content/datasets/data_in/objects/sim/segm/{dataset_index}/clone\"\n",
    "\n",
    "\n",
    "  txt_file_path = f'./content/datasets/data_in/encodings/{dataset_index}_clone_scenegt_rgb_encoding.txt'\n",
    "  color_to_class_id_mapping = parse_txt_file(txt_file_path)\n",
    "\n",
    "  # Read the ground truth labels from the text file\n",
    "  with open(labels_file, 'r') as f:\n",
    "      lines = f.readlines()[1:]  # Skip the header line\n",
    "\n",
    "  # Dictionary to store bounding boxes or labels for each image index\n",
    "  ground_truth_data = {}\n",
    "\n",
    "  image_files = sorted(os.listdir(images_folder))\n",
    "  max_index=int(image_files[-1].strip().split('.png')[0])\n",
    "  for index in range(0,max_index+1):\n",
    "    if index not in ground_truth_data:\n",
    "                  ground_truth_data[index] = []\n",
    "  # Process ground truth lines and group them by image index\n",
    "  for line in lines:\n",
    "      line_parts = line.strip().split(' ')\n",
    "      image_index = int(line_parts[0])\n",
    "\n",
    "      if(image_index<=stop or stop==0):\n",
    "          label = line_parts[2]\n",
    "\n",
    "          if label != 'DontCare':\n",
    "              x_min = int(float(line_parts[6]))\n",
    "              y_min = int(float(line_parts[7]))\n",
    "              x_max = int(float(line_parts[8]))\n",
    "              y_max = int(float(line_parts[9]))\n",
    "\n",
    "              # Save bounding box or label in the dictionary\n",
    "\n",
    "              ground_truth_data[image_index].append((label, x_min, y_min, x_max, y_max))\n",
    "\n",
    "  # Process images in the sorted order\n",
    "  for image_index in sorted(ground_truth_data.keys()):\n",
    "      if(image_index%50==0):\n",
    "        print(image_index)\n",
    "      image_file = sorted(os.listdir(images_folder))[image_index]\n",
    "      image_path = os.path.join(images_folder, image_file)\n",
    "      image = cv2.imread(image_path)\n",
    "      raw_image_sim.append(image)\n",
    "\n",
    "\n",
    "\n",
    "      bounding_boxes = ground_truth_data[image_index]\n",
    "      image2 = image.copy()\n",
    "\n",
    "      for label, x_min, y_min, x_max, y_max in bounding_boxes:\n",
    "          if x_max > x_min and y_max > y_min:\n",
    "              cv2.rectangle(image2, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
    "              cv2.putText(image2, label, (x_min, y_min - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "              bounding_boxes_list_sim.append((image_index,label, x_min, y_min, x_max, y_max))\n",
    "\n",
    "\n",
    "      segmentation_mask_file = f\"{os.path.splitext(image_file)[0]}.png\"\n",
    "      segmentation_mask_path = os.path.join(segmentation_masks_folder, segmentation_mask_file)\n",
    "      if os.path.exists(segmentation_mask_path):\n",
    "          segmentation_mask = cv2.imread(segmentation_mask_path)\n",
    "\n",
    "          images_list_index_sim.append(image_index)\n",
    "          images_list_sim.append(image2)\n",
    "          semantic_id = rgb_mask_to_class_ids(segmentation_mask[:,:,::-1], color_to_class_id_mapping,label_id_mapping)\n",
    "          if(color_map):\n",
    "            colored_mask = np.zeros_like(image)\n",
    "            colored_mask[:, :, 0] = np.vectorize(map_to_b)(semantic_id)\n",
    "            colored_mask[:, :, 1] = np.vectorize(map_to_g)(semantic_id)\n",
    "            colored_mask[:, :, 2] = np.vectorize(map_to_r)(semantic_id)\n",
    "            segmentation_masks_list_sim.append(colored_mask)\n",
    "            if(visualize):\n",
    "              overlay = cv2.addWeighted(image, 0.7, segmentation_mask, 0.3, 0)\n",
    "              plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "              plt.show()\n",
    "              plt.imshow(cv2.cvtColor(segmentation_mask, cv2.COLOR_BGR2RGB))\n",
    "              plt.show()\n",
    "              plt.imshow(cv2.cvtColor(colored_mask, cv2.COLOR_BGR2RGB))\n",
    "              plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "          semantic_id_list_sim.append(semantic_id)\n",
    "\n",
    "  return images_list_index_sim,images_list_sim,segmentation_masks_list_sim,semantic_id_list_sim,bounding_boxes_list_sim,raw_image_sim\n",
    "\n",
    "def save_dictionary_to_h5(file_path, data_dict):\n",
    "    with h5py.File(file_path, 'w') as hf:\n",
    "        for key, array_list in data_dict.items():\n",
    "            # Create a group for each key in the dictionary\n",
    "            group = hf.create_group(key)\n",
    "            for i, arr in enumerate(array_list):\n",
    "                # Save each array as a dataset within the group\n",
    "                group.create_dataset(f'array_{i}', data=arr)\n",
    "\n",
    "\n",
    "def save_dictionary_to_h5_bounding(file_path, data_dict):\n",
    "    with h5py.File(file_path, 'w') as hf:\n",
    "        for key, array_list in data_dict.items():\n",
    "            # Create a group for each key in the dictionary\n",
    "            group = hf.create_group(key)\n",
    "            for i, arr in enumerate(array_list):\n",
    "                # Save each array as a dataset within the group\n",
    "                output=[0,0,0,0,0,0]\n",
    "                if(arr[1]=='Car'):\n",
    "                  output[1]=3\n",
    "                else:\n",
    "                  output[1]=0\n",
    "                output[2]=arr[2]\n",
    "                output[3]=arr[3]\n",
    "                output[4]=arr[4]\n",
    "                output[5]=arr[5]\n",
    "                output[0]=arr[0]\n",
    "                group.create_dataset(f'array_{i}', data=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 595
    },
    "id": "wsOVDH0dJ7Q4",
    "outputId": "db46d670-bcc4-4a30-f055-6f4bdfc96c0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-STARTING real-  0001\n",
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "-STARTING sim-  0001\n",
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "-DONE-  0001\n",
      "-STARTING real-  0002\n",
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "-STARTING sim-  0002\n",
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "-DONE-  0002\n",
      "-STARTING real-  0006\n",
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "-STARTING sim-  0006\n",
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "-DONE-  0006\n",
      "-STARTING real-  0018\n",
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "-STARTING sim-  0018\n",
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "-DONE-  0018\n",
      "-STARTING real-  0020\n",
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "-STARTING sim-  0020\n",
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "-DONE-  0020\n"
     ]
    }
   ],
   "source": [
    "images_list_sim = {}\n",
    "bounding_boxes_list_sim = {}\n",
    "segmentation_masks_list_sim = {}\n",
    "images_list_index_sim = {}\n",
    "semantic_id_list_sim = {}\n",
    "raw_image_sim = {}\n",
    "\n",
    "\n",
    "images_list_real = {}\n",
    "bounding_boxes_list_real = {}\n",
    "segmentation_masks_list_real = {}\n",
    "images_list_index_real = {}\n",
    "semantic_id_list_real = {}\n",
    "raw_image_real = {}\n",
    "\n",
    "\n",
    "\n",
    "dataset_index_list=[\"0001\",\"0002\",\"0006\",\"0018\",\"0020\"]\n",
    "\n",
    "for dataset_index in dataset_index_list:\n",
    "  print(\"-STARTING real- \", dataset_index)\n",
    "  images_list_index_real_out,images_list_real_out,segmentation_masks_list_real_out,semantic_id_list_real_out,bounding_boxes_list_real_out,raw_image_real_out=load_real_data(dataset_index,visualize=False,stop=0,color_map=True)\n",
    "  images_list_real[dataset_index] = images_list_real_out\n",
    "  bounding_boxes_list_real[dataset_index] = bounding_boxes_list_real_out\n",
    "  segmentation_masks_list_real[dataset_index] = segmentation_masks_list_real_out\n",
    "  images_list_index_real[dataset_index] = images_list_index_real_out\n",
    "  semantic_id_list_real[dataset_index] = semantic_id_list_real_out\n",
    "  raw_image_real[dataset_index] = raw_image_real_out\n",
    "  print(\"-STARTING sim- \", dataset_index)\n",
    "\n",
    "  images_list_index_sim_out,images_list_sim_out,segmentation_masks_list_sim_out,semantic_id_list_sim_out,bounding_boxes_list_sim_out,raw_image_sim_out=load_sim_data(dataset_index,visualize=False,stop=0,color_map=True)\n",
    "  images_list_sim[dataset_index] = images_list_sim_out\n",
    "  bounding_boxes_list_sim[dataset_index] = bounding_boxes_list_sim_out\n",
    "  segmentation_masks_list_sim[dataset_index] = segmentation_masks_list_sim_out\n",
    "  images_list_index_sim[dataset_index] = images_list_index_sim_out\n",
    "  semantic_id_list_sim[dataset_index] = semantic_id_list_sim_out\n",
    "  raw_image_sim[dataset_index] = raw_image_sim_out\n",
    "  print(\"-DONE- \", dataset_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Up1ZD4u45mYx",
    "outputId": "6861396f-c132-4d45-fef2-ed9820c2b44b"
   },
   "outputs": [],
   "source": [
    "desired_semantic_id = 0\n",
    "\n",
    "dataset_index_list=[\"0001\",\"0002\",\"0006\",\"0018\",\"0020\"]\n",
    "for dataset_index in dataset_index_list:\n",
    "\n",
    "  print(dataset_index)\n",
    "  for i in range(0, 10):\n",
    "      print(i)\n",
    "      # Create a 2x2 grid of subplots\n",
    "      fig, axs = plt.subplots(3, 3, figsize=(15, 6))\n",
    "      plt.subplots_adjust(wspace=0.2, hspace=0.4)\n",
    "\n",
    "      # Plot the real and fake images side by side in the first row\n",
    "      axs[0, 0].imshow(cv2.cvtColor(raw_image_real[dataset_index][i], cv2.COLOR_BGR2RGB))\n",
    "      axs[0, 0].set_title('Real Image')\n",
    "      axs[0, 1].imshow(cv2.cvtColor(raw_image_sim[dataset_index][i], cv2.COLOR_BGR2RGB))\n",
    "      axs[0, 1].set_title('Sim Image')\n",
    "\n",
    "      # Plot the real and fake segmentation masks side by side in the second row\n",
    "      axs[1, 0].imshow(cv2.cvtColor(segmentation_masks_list_real[dataset_index][i], cv2.COLOR_BGR2RGB))\n",
    "      axs[1, 0].set_title('Real Segmentation Mask')\n",
    "      axs[1, 1].imshow(cv2.cvtColor(segmentation_masks_list_sim[dataset_index][i], cv2.COLOR_BGR2RGB))\n",
    "      axs[1, 1].set_title('Sim Segmentation Mask')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "      # Create binary masks for the desired semantic ID in real and fake masks\n",
    "      binary_mask_real = (semantic_id_list_real[dataset_index][i] == desired_semantic_id).astype(np.uint8)\n",
    "      binary_mask_fake = (semantic_id_list_sim[dataset_index][i] == desired_semantic_id).astype(np.uint8)\n",
    "\n",
    "\n",
    "      diff_mask_road=abs(binary_mask_fake-binary_mask_real)\n",
    "      diff_mask_all=abs(segmentation_masks_list_sim[dataset_index][i]-segmentation_masks_list_real[dataset_index][i])\n",
    "\n",
    "      axs[1, 2].imshow(cv2.cvtColor(diff_mask_all, cv2.COLOR_BGR2RGB))\n",
    "      axs[1, 2].set_title('Diff Segmentation Mask')\n",
    "\n",
    "      axs[2, 0].imshow(binary_mask_real, cmap='gray')\n",
    "      axs[2, 0].set_title('Real Road Mask')\n",
    "\n",
    "      axs[2, 1].imshow(binary_mask_fake, cmap='gray')\n",
    "      axs[2, 1].set_title('Sim Road Mask')\n",
    "\n",
    "      axs[2, 2].imshow(diff_mask_road, cmap='gray')\n",
    "      axs[2, 2].set_title('Diff Road Mask')\n",
    "\n",
    "      for ax in axs.flat:\n",
    "          ax.set_xticks([])\n",
    "          ax.set_yticks([])\n",
    "\n",
    "      # Show the plot for the current iteration\n",
    "      plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "kRtCyE6GX6Qb"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "!mkdir outputs\n",
    "with open('./content/datasets/pkl_out/images_list_sim.pkl', 'wb') as file:\n",
    "    pickle.dump(images_list_sim, file)\n",
    "\n",
    "with open('./content/datasets/pkl_out/bounding_boxes_list_sim.pkl', 'wb') as file:\n",
    "    pickle.dump(bounding_boxes_list_sim, file)\n",
    "\n",
    "with open('./content/datasets/pkl_out/segmentation_masks_list_sim.pkl', 'wb') as file:\n",
    "    pickle.dump(segmentation_masks_list_sim, file)\n",
    "\n",
    "with open('./content/datasets/pkl_out/semantic_id_list_sim.pkl', 'wb') as file:\n",
    "    pickle.dump(semantic_id_list_sim, file)\n",
    "with open('./content/datasets/pkl_out/raw_image_sim.pkl', 'wb') as file:\n",
    "    pickle.dump(raw_image_sim, file)\n",
    "\n",
    "with open('./content/datasets/pkl_out/bounding_boxes_list_real.pkl', 'wb') as file:\n",
    "    pickle.dump(bounding_boxes_list_real, file)\n",
    "\n",
    "with open('./content/datasets/pkl_out/segmentation_masks_list_real.pkl', 'wb') as file:\n",
    "    pickle.dump(segmentation_masks_list_real, file)\n",
    "with open('./content/datasets/pkl_out/semantic_id_list_real.pkl', 'wb') as file:\n",
    "    pickle.dump(semantic_id_list_real, file)\n",
    "with open('./content/datasets/pkl_out/raw_image_real.pkl', 'wb') as file:\n",
    "    pickle.dump(raw_image_real, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "An4Iyt4Mh3tt"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./content/datasets/pkl_out/raw_image_sim.pkl', 'rb') as file:\n",
    "    loaded_dictionary_images_sim = pickle.load(file)\n",
    "with open('./content/datasets/pkl_out/segmentation_masks_list_sim.pkl', 'rb') as file:\n",
    "    loaded_segmentation_masks_sim = pickle.load(file)\n",
    "with open('./content/datasets/pkl_out/semantic_id_list_sim.pkl', 'rb') as file:\n",
    "    loaded_semantic_id_sim = pickle.load(file)\n",
    "\n",
    "with open('./content/datasets/pkl_out/raw_image_real.pkl', 'rb') as file:\n",
    "    loaded_dictionary_images_real = pickle.load(file)\n",
    "with open('./content/datasets/pkl_out/segmentation_masks_list_real.pkl', 'rb') as file:\n",
    "    loaded_segmentation_masks_real = pickle.load(file)\n",
    "with open('./content/datasets/pkl_out/semantic_id_list_real.pkl', 'rb') as file:\n",
    "    loaded_semantic_id_real = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zA9RlJtADQHu",
    "outputId": "34336fa3-e809-4c09-c207-3d458f479b81"
   },
   "outputs": [],
   "source": [
    "file_path = './content/datasets/h5_out/raw_image_sim.h5'\n",
    "save_dictionary_to_h5(file_path, loaded_dictionary_images_sim)\n",
    "\n",
    "file_path = './content/datasets/h5_out/raw_image_real.h5'\n",
    "save_dictionary_to_h5(file_path, loaded_dictionary_images_real)\n",
    "\n",
    "file_path = './content/datasets/h5_out/segmentation_masks_list_sim.h5'\n",
    "save_dictionary_to_h5(file_path, loaded_segmentation_masks_sim)\n",
    "\n",
    "file_path = './content/datasets/h5_out/segmentation_masks_list_real.h5'\n",
    "save_dictionary_to_h5(file_path, loaded_segmentation_masks_real)\n",
    "\n",
    "file_path = './content/datasets/h5_out/semantic_id_list_sim.h5'\n",
    "save_dictionary_to_h5(file_path, loaded_semantic_id_sim)\n",
    "\n",
    "file_path = './content/datasets/h5_out/semantic_id_list_real.h5'\n",
    "save_dictionary_to_h5(file_path, loaded_semantic_id_real)\n",
    "print(bounding_boxes_list_sim)\n",
    "\n",
    "file_path = './content/datasets/h5_out/bounding_boxes_sim.h5'\n",
    "save_dictionary_to_h5_bounding(file_path, bounding_boxes_list_sim)\n",
    "\n",
    "file_path = './content/datasets/h5_out/bounding_boxes_real.h5'\n",
    "save_dictionary_to_h5_bounding(file_path, bounding_boxes_list_real)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0f122d49862b437b95c0317503acee4b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_510deb9127754ec8b1a06ca73f5acab2",
      "max": 14563152,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_632e31d0691941b0a649e8de5baec3fc",
      "value": 14563152
     }
    },
    "1d843e18dab742b4b58bf50ff426fdd2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2157955bf53646e7b347adec3e44aa4a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2a02a5f4a625405886793b93856f12d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3f60f87dab934d89b198e65e023bc9b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "510deb9127754ec8b1a06ca73f5acab2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "632e31d0691941b0a649e8de5baec3fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "70e51f43aca14059b8e6ff8cd8828bbf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7255ecf9a6e44ae6a1d2d317c7d18169": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "75367f7d21824749baf627dbc77ca7ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "792bfcb81195415a820191e0b07c923f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7ee71a68ae704d7491f9e5371e5cd526": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c93d7f579d9342f7a3a69bf75fb0ac36",
      "placeholder": "​",
      "style": "IPY_MODEL_3f60f87dab934d89b198e65e023bc9b3",
      "value": " 14.6M/14.6M [00:00&lt;00:00, 44.7MB/s]"
     }
    },
    "9e812626ca3a457fbbb92cf0df6c7f57": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a21248437cb142aab84404b2e64203fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a71b7a587bd64dbfa8c8fb4973625142": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_70e51f43aca14059b8e6ff8cd8828bbf",
      "max": 70043,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2a02a5f4a625405886793b93856f12d1",
      "value": 70043
     }
    },
    "a7cfeef29aa443a383f839024bd9377a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_af859a465f1d40d186c0dfa9facdadf2",
       "IPY_MODEL_0f122d49862b437b95c0317503acee4b",
       "IPY_MODEL_7ee71a68ae704d7491f9e5371e5cd526"
      ],
      "layout": "IPY_MODEL_7255ecf9a6e44ae6a1d2d317c7d18169"
     }
    },
    "af859a465f1d40d186c0dfa9facdadf2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2157955bf53646e7b347adec3e44aa4a",
      "placeholder": "​",
      "style": "IPY_MODEL_75367f7d21824749baf627dbc77ca7ae",
      "value": "Downloading tf_model.h5: 100%"
     }
    },
    "b70c274750a04976b738a463a3962965": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_792bfcb81195415a820191e0b07c923f",
      "placeholder": "​",
      "style": "IPY_MODEL_c9f338ae5d1940b5a77b612430bf9984",
      "value": " 70.0k/70.0k [00:00&lt;00:00, 1.46MB/s]"
     }
    },
    "c1a23b93eed54aadabcf3284553272f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1d843e18dab742b4b58bf50ff426fdd2",
      "placeholder": "​",
      "style": "IPY_MODEL_a21248437cb142aab84404b2e64203fc",
      "value": "Downloading (…)lve/main/config.json: 100%"
     }
    },
    "c93d7f579d9342f7a3a69bf75fb0ac36": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c9f338ae5d1940b5a77b612430bf9984": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dd38f19dd15a40cf9c6e9129b4788578": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c1a23b93eed54aadabcf3284553272f9",
       "IPY_MODEL_a71b7a587bd64dbfa8c8fb4973625142",
       "IPY_MODEL_b70c274750a04976b738a463a3962965"
      ],
      "layout": "IPY_MODEL_9e812626ca3a457fbbb92cf0df6c7f57"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
